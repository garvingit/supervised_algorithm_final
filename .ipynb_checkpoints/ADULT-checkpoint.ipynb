{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_style('white')  # plot formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "                \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n",
    "                \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income\"\n",
    "               ]\n",
    "df = pd.read_csv(\"datasets/adult.data\", header=0, names=column_names, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32560, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the shape of dataset, num observations and features\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "1   38            Private  215646     HS-grad              9   \n",
       "2   53            Private  234721        11th              7   \n",
       "3   28            Private  338409   Bachelors             13   \n",
       "4   37            Private  284582     Masters             14   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "1             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "2   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "3   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "4   Married-civ-spouse     Exec-managerial            Wife   White   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country  income  \n",
       "0             0             0              13   United-States   <=50K  \n",
       "1             0             0              40   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40            Cuba   <=50K  \n",
       "4             0             0              40   United-States   <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()#data looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education_num     0\n",
       "marital_status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital_gain      0\n",
       "capital_loss      0\n",
       "hours_per_week    0\n",
       "native_country    0\n",
       "income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for any null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformIncome(string):\n",
    "    income = df['income'].unique() #[' <=50K', ' >50K']\n",
    "    \n",
    "    #classify <=50k is 0 and >50k is 1 pos\n",
    "    if string == income[1]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['income'] = df['income'].apply(transformIncome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24719\n",
       "1     7841\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#positive and negative classes\n",
    "df['income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32560 entries, 0 to 32559\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32560 non-null  int64 \n",
      " 1   workclass       32560 non-null  object\n",
      " 2   fnlwgt          32560 non-null  int64 \n",
      " 3   education       32560 non-null  object\n",
      " 4   education_num   32560 non-null  int64 \n",
      " 5   marital_status  32560 non-null  object\n",
      " 6   occupation      32560 non-null  object\n",
      " 7   relationship    32560 non-null  object\n",
      " 8   race            32560 non-null  object\n",
      " 9   sex             32560 non-null  object\n",
      " 10  capital_gain    32560 non-null  int64 \n",
      " 11  capital_loss    32560 non-null  int64 \n",
      " 12  hours_per_week  32560 non-null  int64 \n",
      " 13  native_country  32560 non-null  object\n",
      " 14  income          32560 non-null  int64 \n",
      "dtypes: int64(7), object(8)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting features and target\n",
    "X = df.drop(['income'], axis=1)\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>?</th>\n",
       "      <th>Federal-gov</th>\n",
       "      <th>Local-gov</th>\n",
       "      <th>Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Puerto-Rico</th>\n",
       "      <th>Scotland</th>\n",
       "      <th>South</th>\n",
       "      <th>Taiwan</th>\n",
       "      <th>Thailand</th>\n",
       "      <th>Trinadad&amp;Tobago</th>\n",
       "      <th>United-States</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.837097</td>\n",
       "      <td>-1.008742</td>\n",
       "      <td>1.134779</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-2.222120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.042640</td>\n",
       "      <td>0.245046</td>\n",
       "      <td>-0.420027</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-0.035430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.057031</td>\n",
       "      <td>0.425770</td>\n",
       "      <td>-1.197429</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-0.035430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.775755</td>\n",
       "      <td>1.408146</td>\n",
       "      <td>1.134779</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-0.035430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.115952</td>\n",
       "      <td>0.898170</td>\n",
       "      <td>1.523480</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-0.035430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>-0.849066</td>\n",
       "      <td>0.639710</td>\n",
       "      <td>0.746077</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-0.197407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>0.103982</td>\n",
       "      <td>-0.335466</td>\n",
       "      <td>-0.420027</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-0.035430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>1.423589</td>\n",
       "      <td>-0.358811</td>\n",
       "      <td>-0.420027</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-0.035430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>-1.215624</td>\n",
       "      <td>0.110927</td>\n",
       "      <td>-0.420027</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-1.655200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>0.983720</td>\n",
       "      <td>0.929862</td>\n",
       "      <td>-0.420027</td>\n",
       "      <td>1.888401</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-0.035430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32560 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "0      0.837097 -1.008742       1.134779     -0.145914     -0.216663   \n",
       "1     -0.042640  0.245046      -0.420027     -0.145914     -0.216663   \n",
       "2      1.057031  0.425770      -1.197429     -0.145914     -0.216663   \n",
       "3     -0.775755  1.408146       1.134779     -0.145914     -0.216663   \n",
       "4     -0.115952  0.898170       1.523480     -0.145914     -0.216663   \n",
       "...         ...       ...            ...           ...           ...   \n",
       "32555 -0.849066  0.639710       0.746077     -0.145914     -0.216663   \n",
       "32556  0.103982 -0.335466      -0.420027     -0.145914     -0.216663   \n",
       "32557  1.423589 -0.358811      -0.420027     -0.145914     -0.216663   \n",
       "32558 -1.215624  0.110927      -0.420027     -0.145914     -0.216663   \n",
       "32559  0.983720  0.929862      -0.420027      1.888401     -0.216663   \n",
       "\n",
       "       hours_per_week    ?   Federal-gov   Local-gov   Never-worked  ...  \\\n",
       "0           -2.222120  0.0           0.0         0.0            0.0  ...   \n",
       "1           -0.035430  0.0           0.0         0.0            0.0  ...   \n",
       "2           -0.035430  0.0           0.0         0.0            0.0  ...   \n",
       "3           -0.035430  0.0           0.0         0.0            0.0  ...   \n",
       "4           -0.035430  0.0           0.0         0.0            0.0  ...   \n",
       "...               ...  ...           ...         ...            ...  ...   \n",
       "32555       -0.197407  0.0           0.0         0.0            0.0  ...   \n",
       "32556       -0.035430  0.0           0.0         0.0            0.0  ...   \n",
       "32557       -0.035430  0.0           0.0         0.0            0.0  ...   \n",
       "32558       -1.655200  0.0           0.0         0.0            0.0  ...   \n",
       "32559       -0.035430  0.0           0.0         0.0            0.0  ...   \n",
       "\n",
       "        Portugal   Puerto-Rico   Scotland   South   Taiwan   Thailand  \\\n",
       "0            0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "1            0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "2            0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "3            0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "4            0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "...          ...           ...        ...     ...      ...        ...   \n",
       "32555        0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "32556        0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "32557        0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "32558        0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "32559        0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "\n",
       "        Trinadad&Tobago   United-States   Vietnam   Yugoslavia  \n",
       "0                   0.0             1.0       0.0          0.0  \n",
       "1                   0.0             1.0       0.0          0.0  \n",
       "2                   0.0             1.0       0.0          0.0  \n",
       "3                   0.0             0.0       0.0          0.0  \n",
       "4                   0.0             1.0       0.0          0.0  \n",
       "...                 ...             ...       ...          ...  \n",
       "32555               0.0             1.0       0.0          0.0  \n",
       "32556               0.0             1.0       0.0          0.0  \n",
       "32557               0.0             1.0       0.0          0.0  \n",
       "32558               0.0             1.0       0.0          0.0  \n",
       "32559               0.0             1.0       0.0          0.0  \n",
       "\n",
       "[32560 rows x 106 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoric_features = [\"workclass\", \"education\", \"marital_status\", \n",
    "                      \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\"]\n",
    "numeric_features = [\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n",
    "\n",
    "#one hot encoder and scaler\n",
    "scaler = StandardScaler()\n",
    "ohe    = OneHotEncoder(sparse=False)\n",
    "\n",
    "#scaling numeric columns\n",
    "scaled_columns = pd.DataFrame(scaler.fit_transform(X[numeric_features]), \n",
    "                                columns=numeric_features, \n",
    "                                index=X.index)\n",
    "encoded_columns = ohe.fit_transform(X[categoric_features])#turns to dense matrix\n",
    "\n",
    "# Concatenate them back together\n",
    "for index, category in enumerate(np.concatenate(ohe.categories_)):\n",
    "    scaled_columns[category] = encoded_columns[:, index]\n",
    "    \n",
    "scaled_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>?</th>\n",
       "      <th>Federal-gov</th>\n",
       "      <th>Local-gov</th>\n",
       "      <th>Never-worked</th>\n",
       "      <th>...</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Puerto-Rico</th>\n",
       "      <th>Scotland</th>\n",
       "      <th>South</th>\n",
       "      <th>Taiwan</th>\n",
       "      <th>Thailand</th>\n",
       "      <th>Trinadad&amp;Tobago</th>\n",
       "      <th>United-States</th>\n",
       "      <th>Vietnam</th>\n",
       "      <th>Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.837097</td>\n",
       "      <td>-1.008742</td>\n",
       "      <td>1.134779</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-2.22212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.042640</td>\n",
       "      <td>0.245046</td>\n",
       "      <td>-0.420027</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-0.03543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.057031</td>\n",
       "      <td>0.425770</td>\n",
       "      <td>-1.197429</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-0.03543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.775755</td>\n",
       "      <td>1.408146</td>\n",
       "      <td>1.134779</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-0.03543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.115952</td>\n",
       "      <td>0.898170</td>\n",
       "      <td>1.523480</td>\n",
       "      <td>-0.145914</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-0.03543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "0  0.837097 -1.008742       1.134779     -0.145914     -0.216663   \n",
       "1 -0.042640  0.245046      -0.420027     -0.145914     -0.216663   \n",
       "2  1.057031  0.425770      -1.197429     -0.145914     -0.216663   \n",
       "3 -0.775755  1.408146       1.134779     -0.145914     -0.216663   \n",
       "4 -0.115952  0.898170       1.523480     -0.145914     -0.216663   \n",
       "\n",
       "   hours_per_week    ?   Federal-gov   Local-gov   Never-worked  ...  \\\n",
       "0        -2.22212  0.0           0.0         0.0            0.0  ...   \n",
       "1        -0.03543  0.0           0.0         0.0            0.0  ...   \n",
       "2        -0.03543  0.0           0.0         0.0            0.0  ...   \n",
       "3        -0.03543  0.0           0.0         0.0            0.0  ...   \n",
       "4        -0.03543  0.0           0.0         0.0            0.0  ...   \n",
       "\n",
       "    Portugal   Puerto-Rico   Scotland   South   Taiwan   Thailand  \\\n",
       "0        0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "1        0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "2        0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "3        0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "4        0.0           0.0        0.0     0.0      0.0        0.0   \n",
       "\n",
       "    Trinadad&Tobago   United-States   Vietnam   Yugoslavia  \n",
       "0               0.0             1.0       0.0          0.0  \n",
       "1               0.0             1.0       0.0          0.0  \n",
       "2               0.0             1.0       0.0          0.0  \n",
       "3               0.0             0.0       0.0          0.0  \n",
       "4               0.0             1.0       0.0          0.0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_preprocessed=scaled_columns\n",
    "X_preprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "1   38            Private  215646     HS-grad              9   \n",
       "2   53            Private  234721        11th              7   \n",
       "3   28            Private  338409   Bachelors             13   \n",
       "4   37            Private  284582     Masters             14   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "1             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "2   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "3   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "4   Married-civ-spouse     Exec-managerial            Wife   White   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country  \n",
       "0             0             0              13   United-States  \n",
       "1             0             0              40   United-States  \n",
       "2             0             0              40   United-States  \n",
       "3             0             0              40            Cuba  \n",
       "4             0             0              40   United-States  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()#unchanged for random forest, and decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32560, 14)\n",
      "14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>2925</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>14085</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>15335</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>19354</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>17699</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  education_num  marital_status  \\\n",
       "0   33          6    2925          9             12               2   \n",
       "1   21          4   14085         11              8               0   \n",
       "2   36          4   15335          1              6               2   \n",
       "3   11          4   19354          9             12               2   \n",
       "4   20          4   17699         12             13               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital_gain  capital_loss  \\\n",
       "0           4             0     4    1             0             0   \n",
       "1           6             1     4    1             0             0   \n",
       "2           6             0     2    1             0             0   \n",
       "3          10             5     2    0             0             0   \n",
       "4           4             5     4    0             0             0   \n",
       "\n",
       "   hours_per_week  native_country  \n",
       "0              12              39  \n",
       "1              39              39  \n",
       "2              39              39  \n",
       "3              39               5  \n",
       "4              39              39  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_labelencode = X.apply(LabelEncoder().fit_transform)\n",
    "print(X_labelencode.shape)\n",
    "print(len(X.columns))\n",
    "X_labelencode.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression (LOGREG): we train both\n",
    "unregularized and regularized models, varying the\n",
    "ridge (regularization) parameter by factors of 10 from\n",
    "10^−8\n",
    "to 10^4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOGREG(X, y):\n",
    "    '''returns the scores of each trial'''\n",
    "    \n",
    "    pipe = Pipeline(steps=[('classifier', LogisticRegression())])\n",
    "\n",
    "    search_space = [{'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                     'classifier__solver': ['saga'],\n",
    "                     'classifier__penalty': ['l1', 'l2'],\n",
    "                     'classifier__C': np.logspace(-8, 4, 13)},\n",
    "                    {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                     'classifier__solver': ['lbfgs'],\n",
    "                     'classifier__penalty': ['l2'],\n",
    "                     'classifier__C': np.logspace(-8, 4, 13)},\n",
    "                    {'classifier': [LogisticRegression(max_iter=5000)],\n",
    "                     'classifier__solver': ['lbfgs','saga'],\n",
    "                     'classifier__penalty': ['none']}\n",
    "                    ]\n",
    "    \n",
    "    TRIALS = 5#DOING 5 TRIALS\n",
    "    log_test_acc = []#saving the accuracy for each logistic regression trial on test set\n",
    "    log_test_auc = []#saving the roc auc for each logistic regression trial on test set\n",
    "    log_test_f1 = []#saving the f1 score for each logistic regression trial on test set\n",
    "    train_acc = []\n",
    "    train_auc = []\n",
    "    train_f1 = []\n",
    "\n",
    "    for i in range(TRIALS):\n",
    "        #sampling 5000 training size for k-fold\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5000)\n",
    "        \n",
    "        # Create grid search |\n",
    "        clf = GridSearchCV(pipe, search_space, cv=5, \n",
    "                       scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                       verbose=1, n_jobs=-1)\n",
    "        best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "        #top 3 best params model parameters\n",
    "        model_acc = best_model.cv_results_['params'][np.argmin(best_model.cv_results_['rank_test_accuracy'])]\n",
    "        model_auc = best_model.cv_results_['params'][np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr'])]\n",
    "        model_f1 = best_model.cv_results_['params'][np.argmin(best_model.cv_results_['rank_test_f1_micro'])]\n",
    "\n",
    "        model_params = [model_acc, model_auc, model_f1]\n",
    "\n",
    "        #gets the scores for each model and append them to corresponding array\n",
    "        for index, params in enumerate(model_params):\n",
    "            C = 0\n",
    "            try:\n",
    "                C = params['classifier__C']\n",
    "            except KeyError:\n",
    "               pass\n",
    "\n",
    "            solver = params['classifier__solver']\n",
    "            penalty = params['classifier__penalty']\n",
    "\n",
    "            #training best models on validation set\n",
    "            logit_model = LogisticRegression(max_iter=5000)\n",
    "            logit_model.set_params(C=C, solver=solver, penalty=penalty)\n",
    "            logit_model.fit(X_train, y_train) \n",
    "\n",
    "            #get roc_auc, acc and f1 scores on test set\n",
    "            if index == 0:\n",
    "                score = logit_model.score(X_test, y_test)\n",
    "                log_test_acc.append(score)\n",
    "                train_score = logit_model.score(X_train, y_train)\n",
    "                train_acc.append(train_score)\n",
    "\n",
    "            elif index == 1:\n",
    "                roc_score = roc_auc_score(y_test, logit_model.predict_proba(X_test)[:, 1])\n",
    "                log_test_auc.append(roc_score)\n",
    "                train_roc = roc_auc_score(y_train, logit_model.predict_proba(X_train)[:, 1])\n",
    "                train_auc.append(train_roc)\n",
    "\n",
    "            #appending to f1\n",
    "            else:\n",
    "                y_predict = logit_model.predict(X_test)#predictions on test set\n",
    "                f_score = f1_score(y_test, y_predict)\n",
    "                log_test_f1.append(f_score)\n",
    "                f_train = f1_score(y_train, logit_model.predict(X_train))\n",
    "                train_f1.append(f_train)\n",
    "                \n",
    "    return log_test_acc, log_test_auc, log_test_f1, train_acc, train_auc, train_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.8s\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done 205 out of 205 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:    1.6s\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done 205 out of 205 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:    1.5s\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done 205 out of 205 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:    1.8s\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done 205 out of 205 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41 candidates, totalling 205 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 205 out of 205 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8497822931785196, 0.8502902757619739, 0.8488026124818577, 0.8488026124818577, 0.8473875181422351]\n",
      "[0.9040530350632845, 0.9047126261233983, 0.9031994054103619, 0.9054531116989093, 0.9046719109837917]\n",
      "[0.6637973038817605, 0.6547858099062919, 0.6542769434995437, 0.6488581781410635, 0.6428935303107489]\n"
     ]
    }
   ],
   "source": [
    "log_acc, log_auc, log_f1, log_train_acc, log_train_auc, log_train_f1 = LOGREG(X_preprocessed, y)\n",
    "print(log_acc)\n",
    "print(log_auc)\n",
    "print(log_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET PERFORMANCE:\n",
      "      Trial 1   Trial 2   Trial 3   Trial 4   Trial 5\n",
      "ACC  0.849782  0.850290  0.848803  0.848803  0.847388\n",
      "ROC  0.904053  0.904713  0.903199  0.905453  0.904672\n",
      "FSC  0.663797  0.654786  0.654277  0.648858  0.642894\n",
      "\n",
      "TRAIN SET PERFORMANCE:\n",
      "      Trial 1   Trial 2   Trial 3   Trial 4   Trial 5\n",
      "ACC  0.854800  0.859200  0.858400  0.861600  0.852200\n",
      "ROC  0.912258  0.912163  0.915894  0.905462  0.907034\n",
      "FSC  0.679894  0.652174  0.675824  0.658440  0.652235\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"TEST SET PERFORMANCE:\"\"\")\n",
    "scores = pd.DataFrame([log_acc, log_auc, log_f1], \n",
    "                     columns= [\"Trial 1\", \"Trial 2\", \"Trial 3\", \"Trial 4\", \"Trial 5\"])\n",
    "scores.rename(index={0: \"ACC\", 1: \"ROC\", 2: \"FSC\"}, inplace=True)\n",
    "print(scores)\n",
    "print()\n",
    "\n",
    "logt_scores = pd.DataFrame([log_train_acc, log_train_auc, log_train_f1], \n",
    "                     columns= [\"Trial 1\", \"Trial 2\", \"Trial 3\", \"Trial 4\", \"Trial 5\"])\n",
    "logt_scores.rename(index={0: \"ACC\", 1: \"ROC\", 2: \"FSC\"}, inplace=True)\n",
    "print(\"TRAIN SET PERFORMANCE:\")\n",
    "print(logt_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 2: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eplores 30 different values of k, evenly spaced from a range between 1 to 500\n",
    "With different weights: uniform, and distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_model(X, y):\n",
    "    classifier = KNeighborsClassifier()\n",
    "    num_k = np.ceil(np.logspace(0, 2.7, 30)).astype(int)\n",
    "    \n",
    "    search_space = {'n_neighbors': num_k, \n",
    "                      'weights': ['uniform', 'distance']}\n",
    "\n",
    "    TRIALS = 5#DOING 5 TRIALS\n",
    "    acc_scores = []#saving the accuracy for each trial on test set\n",
    "    auc_scores = []#saving the roc auc for each trial on test set\n",
    "    f1_scores = []#saving the f1 score for each trial on test set\n",
    "    train_acc = []\n",
    "    train_auc = []\n",
    "    train_f1 = []\n",
    "    \n",
    "    for i in range(TRIALS):\n",
    "        #sampling 5000 training size for k-fold\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5000)\n",
    "        \n",
    "        # Create grid search\n",
    "        clf = GridSearchCV(classifier, search_space, cv=5, \n",
    "                           scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                           verbose=1, n_jobs=-1)\n",
    "        best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "        #top 3 best params model parameters\n",
    "        model_acc = best_model.cv_results_['params'][np.argmin(best_model.cv_results_['rank_test_accuracy'])]\n",
    "        model_auc = best_model.cv_results_['params'][np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr'])]\n",
    "        model_f1 = best_model.cv_results_['params'][np.argmin(best_model.cv_results_['rank_test_f1_micro'])]\n",
    "\n",
    "        model_params = [model_acc, model_auc, model_f1]\n",
    "\n",
    "        #gets the scores for each model and append them to corresponding array\n",
    "        for index, params in enumerate(model_params):\n",
    "            k = params['n_neighbors']\n",
    "            weight = params['weights']\n",
    "\n",
    "            #training best models on validation set\n",
    "            KNN_model = KNeighborsClassifier()\n",
    "            KNN_model.set_params(n_neighbors=k, weights=weight)\n",
    "            KNN_model.fit(X_train, y_train)#training on 5000 points\n",
    "\n",
    "            #model == model_acc\n",
    "            if index == 0:\n",
    "                score = KNN_model.score(X_test, y_test)\n",
    "                acc_scores.append(score)\n",
    "                train_score = KNN_model.score(X_train, y_train)\n",
    "                train_acc.append(train_score)\n",
    "                \n",
    "            #model_auc\n",
    "            elif index == 1:\n",
    "                roc_score = roc_auc_score(y_test, KNN_model.predict_proba(X_test)[:, 1])\n",
    "                auc_scores.append(roc_score)\n",
    "                train_roc = roc_auc_score(y_train, KNN_model.predict_proba(X_train)[:, 1])\n",
    "                train_auc.append(train_roc)\n",
    "\n",
    "            #appending to f1\n",
    "            else:\n",
    "                y_predict = KNN_model.predict(X_test)#predictions on test set\n",
    "                f_score = f1_score(y_test, y_predict)\n",
    "                f1_scores.append(f_score)\n",
    "                f_train = f1_score(y_train, KNN_model.predict(X_train))\n",
    "                train_f1.append(f_train)\n",
    "    \n",
    "    return acc_scores, auc_scores, f1_scores, train_acc, train_auc, train_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   33.0s\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.5s\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   36.0s\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   31.6s\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   59.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8343613933236574, 0.8348693759071117, 0.8334905660377359, 0.8386066763425254, 0.831422351233672]\n",
      "[0.8898778011184316, 0.8891865851578402, 0.8861805401691228, 0.8907874993629027, 0.8857292783935233]\n",
      "[0.62749898000816, 0.6304506699147382, 0.6165287874989556, 0.6410587475790832, 0.626467277697379]\n"
     ]
    }
   ],
   "source": [
    "knn_acc, knn_auc, knn_f1, knn_train_acc, knn_train_auc, knn_train_f1 = KNN_model(X_preprocessed, y) #using onhotencoded and stnadarized\n",
    "print(knn_acc)\n",
    "print(knn_auc)\n",
    "print(knn_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET PERFORMANCE:\n",
      "      Trial 1   Trial 2   Trial 3   Trial 4   Trial 5\n",
      "ACC  0.834361  0.834869  0.833491  0.838607  0.831422\n",
      "ROC  0.889878  0.889187  0.886181  0.890787  0.885729\n",
      "FSC  0.627499  0.630451  0.616529  0.641059  0.626467\n",
      "\n",
      "TRAIN SET PERFORMANCE:\n",
      "     Trial 1  Trial 2   Trial 3   Trial 4   Trial 5\n",
      "ACC      1.0      1.0  0.848400  0.844600  0.854800\n",
      "ROC      1.0      1.0  1.000000  1.000000  1.000000\n",
      "FSC      1.0      1.0  0.645794  0.669221  0.668493\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"TEST SET PERFORMANCE:\"\"\")\n",
    "k_scores = pd.DataFrame([knn_acc, knn_auc, knn_f1], \n",
    "                     columns= [\"Trial 1\", \"Trial 2\", \"Trial 3\", \"Trial 4\", \"Trial 5\"])\n",
    "k_scores.rename(index={0: \"ACC\", 1: \"ROC\", 2: \"FSC\"}, inplace=True)\n",
    "print(k_scores)\n",
    "print()\n",
    "\n",
    "print(\"TRAIN SET PERFORMANCE:\")\n",
    "kt_scores = pd.DataFrame([knn_train_acc, knn_train_auc, knn_train_f1], \n",
    "                     columns= [\"Trial 1\", \"Trial 2\", \"Trial 3\", \"Trial 4\", \"Trial 5\"])\n",
    "kt_scores.rename(index={0: \"ACC\", 1: \"ROC\", 2: \"FSC\"}, inplace=True)\n",
    "print(kt_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 3: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from caruana paper: \"The\n",
    "forests have 1024 trees. The size of the feature set\n",
    "considered at each split is 1,2,4,6,8,12,16 or 20.\"\n",
    "\n",
    "n_estimators: 1024\\\n",
    "max_features: 1,2,4,6,8,12,16 or 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(X, y):\n",
    "    classifier = RandomForestClassifier()\n",
    "    max_features = [1, 2, 4, 6, 8, 12, 16, 20]\n",
    "    \n",
    "    for feature in max_features:\n",
    "        if feature > len(X.columns):\n",
    "            max_features.remove(feature)\n",
    "            \n",
    "    search_space = {'n_estimators': [1024], 'max_features': max_features}\n",
    "    \n",
    "    TRIALS = 5#DOING 5 TRIALS\n",
    "    acc_scores = []#saving the accuracy for each trial on test set\n",
    "    auc_scores = []#saving the roc auc for each trial on test set\n",
    "    f1_scores = []#saving the f1 score for each trial on test set\n",
    "    train_acc = []\n",
    "    train_auc = []\n",
    "    train_f1 = []\n",
    "    \n",
    "    for i in range(TRIALS):\n",
    "        #sampling 5000 training size for k-fold\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5000)\n",
    "        \n",
    "        # Create grid search\n",
    "        clf = GridSearchCV(classifier, search_space, cv=5, \n",
    "                       scoring=['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False,\n",
    "                       verbose=2, n_jobs=-1)\n",
    "        best_model = clf.fit(X_train, y_train)\n",
    "        \n",
    "        #top 3 best params model parameters\n",
    "        model_acc = best_model.cv_results_['params'][np.argmin(best_model.cv_results_['rank_test_accuracy'])]\n",
    "        model_auc = best_model.cv_results_['params'][np.argmin(best_model.cv_results_['rank_test_roc_auc_ovr'])]\n",
    "        model_f1 = best_model.cv_results_['params'][np.argmin(best_model.cv_results_['rank_test_f1_micro'])]\n",
    "        \n",
    "        model_params = [model_acc, model_auc, model_f1]\n",
    "        \n",
    "        #gets the scores for each model and append them to corresponding array\n",
    "        for index, params in enumerate(model_params):\n",
    "            n_estimators = params['n_estimators']\n",
    "            max_features = params['max_features']\n",
    "            \n",
    "            #train once more on entire validation set\n",
    "            RF_model = RandomForestClassifier(n_estimators=n_estimators, \n",
    "                                                  max_features=max_features)\n",
    "            RF_model.fit(X_train, y_train)\n",
    "            \n",
    "            #scoring on test set using multiple metrics\n",
    "            #model == model_acc\n",
    "            if index == 0:\n",
    "                score = RF_model.score(X_test, y_test)\n",
    "                acc_scores.append(score)\n",
    "                train_score = RF_model.score(X_train, y_train)\n",
    "                train_acc.append(train_score)\n",
    "            \n",
    "            #model_auc\n",
    "            elif index == 1:\n",
    "                roc_score = roc_auc_score(y_test, RF_model.predict_proba(X_test)[:, 1])\n",
    "                auc_scores.append(roc_score)\n",
    "                train_roc = roc_auc_score(y_train, RF_model.predict_proba(X_train)[:, 1])\n",
    "                train_auc.append(train_roc)\n",
    "\n",
    "            #appending to f1\n",
    "            else:\n",
    "                y_predict = RF_model.predict(X_test)#predictions on test set\n",
    "                f_score = f1_score(y_test, y_predict)\n",
    "                f1_scores.append(f_score)\n",
    "                f_train = f1_score(y_train, RF_model.predict(X_train))\n",
    "                train_f1.append(f_train)\n",
    "                \n",
    "    return acc_scores, auc_scores, f1_scores, train_acc, train_auc, train_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   28.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   26.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   27.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   28.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/garvinmo/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   28.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8514513788098694, 0.8528301886792453, 0.8512699564586357, 0.8510522496371553, 0.8516328011611031]\n",
      "[0.9030448150446182, 0.9057948071593664, 0.9041476729693638, 0.9016574003950795, 0.9025540399749467]\n",
      "[0.6685746994848312, 0.6671595202891407, 0.6639822499794559, 0.6597784757811208, 0.6702720154976188]\n"
     ]
    }
   ],
   "source": [
    "rf_acc, rf_auc, rf_f1, rftrain_acc, rftrain_auc, rftrain_f1= RF_model(X_labelencode, y) #one hot encoding bad, use label ecodeded\n",
    "print(rf_acc)\n",
    "print(rf_auc)\n",
    "print(rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET PERFORMANCE:\n",
      "      Trial 1   Trial 2   Trial 3   Trial 4   Trial 5\n",
      "ACC  0.851451  0.852830  0.851270  0.851052  0.851633\n",
      "ROC  0.903045  0.905795  0.904148  0.901657  0.902554\n",
      "FSC  0.668575  0.667160  0.663982  0.659778  0.670272\n",
      "\n",
      "TRAIN SET PERFORMANCE:\n",
      "     Trial 1  Trial 2  Trial 3  Trial 4  Trial 5\n",
      "ACC      1.0      1.0      1.0      1.0      1.0\n",
      "ROC      1.0      1.0      1.0      1.0      1.0\n",
      "FSC      1.0      1.0      1.0      1.0      1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST SET PERFORMANCE:\")\n",
    "rf_scores = pd.DataFrame([rf_acc, rf_auc, rf_f1], \n",
    "                     columns= [\"Trial 1\", \"Trial 2\", \"Trial 3\", \"Trial 4\", \"Trial 5\"])\n",
    "rf_scores.rename(index={0: \"ACC\", 1: \"ROC\", 2: \"FSC\"}, inplace=True)\n",
    "print(rf_scores)\n",
    "print()\n",
    "print(\"TRAIN SET PERFORMANCE:\")\n",
    "rft_scores = pd.DataFrame([rftrain_acc, rftrain_auc, rftrain_f1], \n",
    "                     columns= [\"Trial 1\", \"Trial 2\", \"Trial 3\", \"Trial 4\", \"Trial 5\"])\n",
    "rft_scores.rename(index={0: \"ACC\", 1: \"ROC\", 2: \"FSC\"}, inplace=True)\n",
    "print(rft_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
