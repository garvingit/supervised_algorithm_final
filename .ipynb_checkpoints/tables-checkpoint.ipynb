{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "from scipy import stats #stats.ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1 explaining the datasets\n",
    "\n",
    "Example from caruana:\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/21044142/111542957-9e101980-872f-11eb-90e5-06b61eefcf97.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[PROBLEM, #ATTR, TRAIN SIZE, TEST SIZE, %POSITIVE]\n",
    "adult_d = [\"ADULT\", \"14/106\", 5000, 27560, \"24%\"]\n",
    "letters_d = [\"LETTERS.O\", \"16\", 5000, 15000, \"4%\"]\n",
    "mushroom_d = [\"MUSHROOM\", \"22/117\", 5000, 3123, \"52%\"]\n",
    "weather_d = [\"WEATHER\", \"24/95\", 5000, 51420, \"22%\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1: Description of problems\n",
      "   PROBLEM   #ATTR  TRAIN SIZE  TEST SIZE %POS\n",
      "     ADULT  14/106        5000      27560  24%\n",
      " LETTERS.O      16        5000      15000   4%\n",
      "  MUSHROOM  22/117        5000       3123  52%\n",
      "   WEATHER   24/95        5000      51420  22%\n"
     ]
    }
   ],
   "source": [
    "print(\"Table 1: Description of problems\")\n",
    "problems = [adult_d, letters_d, mushroom_d, weather_d]\n",
    "columns = [\"PROBLEM\", \"#ATTR\", \"TRAIN SIZE\", \"TEST SIZE\", \"%POS\"]\n",
    "table_1 = pd.DataFrame(data=problems, columns=columns)\n",
    "print(table_1.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 2:\\\n",
    "Table 2 giving the mean test set performance across trials for each algorithm/dataset\n",
    "combo, with separate columns for each metric. There will also be a column for the mean\n",
    "performance across metrics. This table should be annotated as in CNM06 using\n",
    "boldface to show the best performing algorithm in each column and * to denote a\n",
    "non-significant difference between best algo and the others.\n",
    "\n",
    "Example: ![image](https://user-images.githubusercontent.com/21044142/111548702-517d0c00-8738-11eb-8d15-aac06cdd08d7.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.91612035, 0.56939285, 0.91180975, 0.79910765]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ROW FOR LOGISTIC REG\n",
    "log_acc_4 = [0.847496,  0.849565,  0.850218,  0.847206,  0.848730,                \n",
    "             0.962331,  0.963064,  0.962064,  0.961997,  0.962331,                \n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             0.854259,  0.853092,  0.853909,  0.853306,  0.852839]\n",
    "log_acc = mean(log_acc_4) #mean of logistic acc\n",
    "\n",
    "log_roc_4 = [0.903878,  0.904139,  0.903968, 0.905178,  0.904846,\n",
    "            0.858444,  0.859928,  0.857098,  0.862397,  0.853068,\n",
    "            1.0,     1.0,      1.0,      1.0,      1.0,\n",
    "            0.884416,  0.884626,  0.885708,  0.884818,  0.883683]\n",
    "log_roc = mean(log_roc_4) #mean of logistic roc\n",
    "\n",
    "log_fsc_4 = [0.658619,  0.662414,  0.660714,  0.648858,  0.651101,\n",
    "            0.000000,  0.000000,  0.000000,  0.000000,  0.000000,\n",
    "            1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "            0.624669,  0.620821,  0.620937,  0.616581,  0.623143]\n",
    "log_fsc = mean(log_fsc_4) #mean of logistic fsc\n",
    "\n",
    "log_metrics = [log_acc, log_fsc, log_roc]\n",
    "log_metrics.append(mean(log_metrics))\n",
    "log_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.90843485, 0.73125705, 0.92984875, 0.85651355]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN metrics\n",
    "knn_acc_4 = [0.837627,  0.836502,  0.836865,  0.833055,  0.836067,\n",
    "            0.992133,  0.989866,  0.990933,  0.991933,  0.990733,\n",
    "            1.0, 1.0,      1.0,      1.0,      1.0,\n",
    "            0.806671  ,0.808401,  0.805970,  0.805115,  0.806826]\n",
    "\n",
    "knn_roc_4 = [0.889834,  0.888025,  0.890112,  0.887853,  0.887768,\n",
    "            0.991464,  0.994721,  0.995173,  0.994100,  0.994624,\n",
    "            1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "            0.839923,  0.831548,  0.839641, 0.840887,  0.831302]\n",
    "\n",
    "knn_fsc_4 = [0.635252,  0.628240,  0.617463,  0.632594,  0.632653,\n",
    "            0.895760,  0.865724,  0.880282,  0.893953,  0.879654,\n",
    "            1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "            0.415766,  0.416877,  0.405865,  0.409531,  0.415527]\n",
    "\n",
    "knn_acc = mean(knn_acc_4)\n",
    "knn_roc = mean(knn_roc_4)\n",
    "knn_fsc = mean(knn_fsc_4)\n",
    "\n",
    "knn_metrics = [knn_acc, knn_fsc, knn_roc]\n",
    "knn_metrics.append(mean(knn_metrics))\n",
    "knn_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.92313995, 0.77135995, 0.94500365, 0.8798345166666667]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RF metrics\n",
    "rf_acc_4 = [0.850689,  0.852721,  0.849746,  0.852068,  0.850798,\n",
    "           0.988066,  0.987799,  0.987866,  0.985666,  0.988866,\n",
    "           1.0 ,     1.0,      1.0,      1.0,      1.0,\n",
    "           0.854045,  0.854259,  0.853656,  0.853948,  0.852606]\n",
    "\n",
    "rf_roc_4 = [0.903035,  0.901272,  0.902482,  0.901470,  0.901587,\n",
    "           0.997133,  0.995457,  0.997112,  0.994531,  0.997793,\n",
    "           1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "           0.882664,  0.882683,  0.879023,  0.882971,  0.880860]\n",
    "\n",
    "rf_fsc_4 = [0.657136,  0.669200,  0.657570,  0.664313,  0.661006,\n",
    "           0.814668,  0.817374,  0.818725,  0.790650,  0.828571,\n",
    "           1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "           0.610177,  0.610259,  0.617980,  0.598914,  0.610656]\n",
    "\n",
    "rf_acc = mean(rf_acc_4)\n",
    "rf_roc = mean(rf_roc_4)\n",
    "rf_fsc = mean(rf_fsc_4)\n",
    "\n",
    "rf_metrics = [rf_acc, rf_fsc, rf_roc]\n",
    "rf_metrics.append(mean(rf_metrics))\n",
    "rf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 2: Test set performance for each algorithm by metric (average over 4 problems)\n",
      "MODEL       ACC       FSC       ROC      MEAN\n",
      "   RF  0.923140  0.771360  0.945004  0.879835\n",
      "  KNN  0.908435  0.731257  0.929849  0.856514\n",
      "   LR  0.916120  0.569393  0.911810  0.799108\n"
     ]
    }
   ],
   "source": [
    "#[MODEL, ACC, FSC, ROC MEAN] #ON TEST SET PERFORMANCE\n",
    "print(\"Table 2: Test set performance for each algorithm by metric (average over 4 problems)\")\n",
    "columns = [\"MODEL\", \"ACC\", \"FSC\", \"ROC\", \"MEAN\"]\n",
    "\n",
    "rf = [\"RF\"] + rf_metrics\n",
    "knn = [\"KNN\"] + knn_metrics\n",
    "lr = [\"LR\"] + log_metrics\n",
    "\n",
    "table_2 = pd.DataFrame(data=[rf, knn, lr], columns=columns)\n",
    "print(table_2.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### table 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 3 giving the mean test set performance across trials for each algorithm/metric\n",
    "combo. Annotated as Table 2 to show best/non-significant differences from best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8031286666666667, 0.6068481333333333, 1.0, 0.7864538, 0.7991076500000001]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression average metrics on each dataset\n",
    "log_adult = [0.847496,  0.849565,  0.850218,  0.847206,  0.848730,\n",
    "            0.903878,  0.904139,  0.903968,  0.905178,  0.904846,\n",
    "            0.658619,  0.662414,  0.660714,  0.648858,  0.651101]\n",
    "log_letters = [0.962331,  0.963064,  0.962064,  0.961997,  0.962331,\n",
    "              0.858444,  0.859928,  0.857098,  0.862397,  0.853068,\n",
    "              0.000000,  0.000000,  0.000000,  0.000000,  0.000000]\n",
    "log_mush = 1.0\n",
    "log_weather = [0.854259,  0.853092,  0.853909,  0.853306,  0.852839,\n",
    "              0.884416,  0.884626,  0.885708,  0.884818,  0.883683,\n",
    "              0.624669,  0.620821,  0.620937,  0.616581,  0.623143]\n",
    "\n",
    "log_adult = mean(log_adult)\n",
    "log_letters = mean(log_letters)\n",
    "log_weather = mean(log_weather)\n",
    "\n",
    "log_data = [log_adult, log_letters, log_mush, log_weather]\n",
    "log_data.append(mean(log_data))\n",
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7846606666666667, 0.9560702, 1.0, 0.6853233333333333, 0.85651355]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#knn average metrics\n",
    "knn_adult = [0.837627,  0.836502,  0.836865, 0.833055,  0.836067,\n",
    "             0.889834,  0.888025,  0.890112, 0.887853,  0.887768,\n",
    "            0.635252,  0.628240,  0.617463,  0.632594,  0.632653]\n",
    "knn_letters = [0.992133,  0.989866,  0.990933,  0.991933,  0.990733,\n",
    "                0.991464,  0.994721,  0.995173,  0.994100,  0.994624,\n",
    "                0.895760,  0.865724, 0.880282,  0.893953,  0.879654]\n",
    "knn_mush = 1.0\n",
    "knn_weather = [0.806671,  0.808401,  0.805970,  0.805115, 0.806826,\n",
    "                0.839923,  0.831548,  0.839641,  0.840887, 0.831302,\n",
    "                0.415766,  0.416877,  0.405865, 0.409531, 0.415527]\n",
    "\n",
    "knn_adult = mean(knn_adult)\n",
    "knn_letters = mean(knn_letters)\n",
    "knn_weather = mean(knn_weather)\n",
    "\n",
    "knn_data = [knn_adult, knn_letters, knn_mush, knn_weather]\n",
    "knn_data.append(mean(knn_data))\n",
    "knn_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8050062, 0.9326851333333334, 1.0, 0.7816467333333333, 0.8798345166666667]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rf average metrics\n",
    "rf_adult = [0.850689,  0.852721,  0.849746,  0.852068,  0.850798,\n",
    "             0.903035,  0.901272,  0.902482,  0.901470,  0.901587,\n",
    "            0.657136,  0.669200,  0.657570,  0.664313,  0.661006]\n",
    "rf_letters = [0.988066,  0.987799,  0.987866,  0.985666,  0.988866,\n",
    "            0.997133,  0.995457,  0.997112,  0.994531,  0.997793,\n",
    "            0.814668,  0.817374,  0.818725,  0.790650,  0.828571]\n",
    "rf_mush = 1.0\n",
    "rf_weather = [0.854045,  0.854259,  0.853656,  0.853948,  0.852606,\n",
    "            0.882664,  0.882683,  0.879023,  0.882971,  0.880860,\n",
    "            0.610177,  0.610259,  0.617980,  0.598914,  0.610656]\n",
    "\n",
    "rf_adult = mean(rf_adult)\n",
    "rf_letters = mean(rf_letters)\n",
    "rf_weather = mean(rf_weather)\n",
    "\n",
    "rf_data = [rf_adult, rf_letters, rf_mush, rf_weather]\n",
    "rf_data.append(mean(rf_data))\n",
    "rf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 3: Performance on each problem  (average over 3 metrics)\n",
      "MODEL     ADULT  LETTER.O  MUSHROOM   WEATHER      MEAN\n",
      "   RF  0.805006  0.932685       1.0  0.781647  0.879835\n",
      "  KNN  0.784661  0.956070       1.0  0.685323  0.856514\n",
      "   LR  0.803129  0.606848       1.0  0.786454  0.799108\n"
     ]
    }
   ],
   "source": [
    "#[MODEL,ADULT,LETTER.O,MUSHROOM,WEATHER,MEAN] #ON TEST SET PERFORMANCE\n",
    "print(\"Table 3: Performance on each problem  (average over 3 metrics)\")\n",
    "columns = [\"MODEL\", \"ADULT\", \"LETTER.O\", \"MUSHROOM\", \"WEATHER\", \"MEAN\"]\n",
    "\n",
    "rf_m = [\"RF\"] + rf_data\n",
    "knn_m = [\"KNN\"] + knn_data\n",
    "lr_m = [\"LR\"] + log_data\n",
    "\n",
    "table_3 = pd.DataFrame(data=[rf_m, knn_m, lr_m], columns=columns)\n",
    "print(table_3.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### table 4:\n",
    "\n",
    "An appendix table showing mean training set performance for the optimal\n",
    "hyperparameters on each of the dataset/algorithm combos and a discussion of the\n",
    "difference between each algorithms’ training and test set performance\n",
    "\n",
    "An appendix table showing mean **training** set performance for the optimal\n",
    "hyperparameters on each of the dataset/algorithm combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.91946, 0.64095535, 0.91863035, 0.8263485666666667]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same as table 2 but on training set\n",
    "#ROW FOR LOGISTIC REG\n",
    "tlog_acc_4 = [0.863600,  0.850200,  0.853400,  0.850000,  0.860200,\n",
    "             0.962400,  0.960200,  0.963200,  0.963400,  0.962400,\n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             0.864000,  0.865600,  0.855400,  0.853800,  0.861400]\n",
    "tlog_acc = mean(tlog_acc_4) #mean of logistic acc\n",
    "\n",
    "tlog_roc_4 = [0.913989,  0.910883,  0.911407,  0.909116,  0.912944,\n",
    "             0.864321,  0.879413,  0.860877,  0.867247,  0.871137,\n",
    "             1.0 ,     1.0,      1.0,      1.0,      1.0,\n",
    "             0.899905,  0.901048,  0.889914,  0.885162,  0.895244]\n",
    "tlog_roc = mean(tlog_roc_4) #mean of logistic roc\n",
    "\n",
    "tlog_fsc_4 = [0.673807,  0.669319,  0.666364,  0.666976,  0.671368,\n",
    "             0.000000,  0.000000,  0.000000,  0.000000,  0.000000,\n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             0.899905,  0.901048,  0.889914,  0.885162,  0.895244]\n",
    "tlog_fsc = mean(tlog_fsc_4) #mean of logistic fsc\n",
    "\n",
    "tlog_metrics = [tlog_acc, tlog_fsc, tlog_roc]\n",
    "tlog_metrics.append(mean(tlog_metrics))\n",
    "tlog_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.966, 0.9528963500000001, 0.99445815, 0.9711181666666667]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN metrics performance on training set\n",
    "tknn_acc_4 = [1.000000,    0.847,  1.000000,  0.999800,   0.8488,\n",
    "               1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             1.0,    0.811,      1.0,   0.8134,      1.0]\n",
    "\n",
    "tknn_roc_4 = [1.000000,    1.000,  1.000000,  0.889163,   1.0000,\n",
    "              1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             1.0,    1.000,      1.0,   1.0000,      1.0]\n",
    "\n",
    "tknn_fsc_4 = [0.691813,    1.000,  0.684473,  0.681641,   1.0000,\n",
    "              1.0,      1.0,      1.0,      1.0,     1.0,\n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             1.0,    1.000,      1.0,   1.0000,      1.0]\n",
    "\n",
    "tknn_acc = mean(tknn_acc_4)\n",
    "tknn_roc = mean(tknn_roc_4)\n",
    "tknn_fsc = mean(tknn_fsc_4)\n",
    "\n",
    "tknn_metrics = [tknn_acc, tknn_fsc, tknn_roc]\n",
    "tknn_metrics.append(mean(tknn_metrics))\n",
    "tknn_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RF metrics on training set\n",
    "trf_acc_4 = [1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "            1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "            1.0,      1.0,      1.0,      1.0,      1.0]\n",
    "\n",
    "trf_roc_4 = [1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "            1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "            1.0,      1.0,      1.0,      1.0,      1.0]\n",
    "\n",
    "trf_fsc_4 = [1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "            1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "            1.0,      1.0,      1.0,      1.0,      1.0]\n",
    "\n",
    "trf_acc = mean(trf_acc_4)\n",
    "trf_roc = mean(trf_roc_4)\n",
    "trf_fsc = mean(trf_fsc_4)\n",
    "\n",
    "trf_metrics = [trf_acc, trf_fsc, trf_roc]\n",
    "trf_metrics.append(mean(trf_metrics))\n",
    "trf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPENDIX TABLE 1: Training set performance by metric (average over 4 problems)\n",
      "MODEL      ACC       FSC       ROC      MEAN\n",
      "   RF  1.00000  1.000000  1.000000  1.000000\n",
      "  KNN  0.96600  0.952896  0.994458  0.971118\n",
      "   LR  0.91946  0.640955  0.918630  0.826349\n"
     ]
    }
   ],
   "source": [
    "#[MODEL, ACC, FSC, ROC MEAN] #ON TEST SET PERFORMANCE\n",
    "print(\"APPENDIX TABLE 1: Training set performance by metric (average over 4 problems)\")\n",
    "columns = [\"MODEL\", \"ACC\", \"FSC\", \"ROC\", \"MEAN\"]\n",
    "\n",
    "app_rf = [\"RF\"] + trf_metrics\n",
    "app_knn = [\"KNN\"] + tknn_metrics\n",
    "app_lr = [\"LR\"] + tlog_metrics\n",
    "\n",
    "apptable_1 = pd.DataFrame(data=[app_rf, app_knn, app_lr], columns=columns)\n",
    "print(apptable_1.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apendix table 2 (TABLE 5)\n",
    "\n",
    "An appendix table with raw test set scores, not just the mean scores of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAW TEST se SCORES on each metric in each trial, this one first is ACC\n",
    "log_raw_acc = [0.847496,  0.849565,  0.850218,  0.847206,  0.848730,\n",
    "              0.962331,  0.963064,  0.962064,  0.961997,  0.962331,\n",
    "               1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "               0.854259,  0.853092,  0.853909,  0.853306,  0.852839]\n",
    "\n",
    "knn_raw_acc = [0.837627,  0.836502,  0.836865,  0.833055,  0.836067,\n",
    "              0.992133,  0.989866,  0.990933,  0.991933,  0.990733,\n",
    "              1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "              0.806671,  0.808401,  0.805970,  0.805115,  0.806826]\n",
    "\n",
    "rf_raw_acc = [0.850689,  0.852721,  0.849746,  0.852068,  0.850798,\n",
    "             0.988066,  0.987799,  0.987866,  0.985666,  0.988866,\n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             0.854045,  0.854259,  0.853656,  0.853948,  0.852606]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPENDIX TABLE 2.1: TEST SET RAW SCORES PERFORMACE ON ACCURACY METRIC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>1ADL</th>\n",
       "      <th>2ADL</th>\n",
       "      <th>3ADL</th>\n",
       "      <th>4ADL</th>\n",
       "      <th>5ADL</th>\n",
       "      <th>1LET</th>\n",
       "      <th>2LET</th>\n",
       "      <th>3LET</th>\n",
       "      <th>4LET</th>\n",
       "      <th>5LET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.850689</td>\n",
       "      <td>0.852721</td>\n",
       "      <td>0.849746</td>\n",
       "      <td>0.852068</td>\n",
       "      <td>0.850798</td>\n",
       "      <td>0.988066</td>\n",
       "      <td>0.987799</td>\n",
       "      <td>0.987866</td>\n",
       "      <td>0.985666</td>\n",
       "      <td>0.988866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.837627</td>\n",
       "      <td>0.836502</td>\n",
       "      <td>0.836865</td>\n",
       "      <td>0.833055</td>\n",
       "      <td>0.836067</td>\n",
       "      <td>0.992133</td>\n",
       "      <td>0.989866</td>\n",
       "      <td>0.990933</td>\n",
       "      <td>0.991933</td>\n",
       "      <td>0.990733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.847496</td>\n",
       "      <td>0.849565</td>\n",
       "      <td>0.850218</td>\n",
       "      <td>0.847206</td>\n",
       "      <td>0.848730</td>\n",
       "      <td>0.962331</td>\n",
       "      <td>0.963064</td>\n",
       "      <td>0.962064</td>\n",
       "      <td>0.961997</td>\n",
       "      <td>0.962331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MODEL      1ADL      2ADL      3ADL      4ADL      5ADL      1LET      2LET  \\\n",
       "0    RF  0.850689  0.852721  0.849746  0.852068  0.850798  0.988066  0.987799   \n",
       "1   KNN  0.837627  0.836502  0.836865  0.833055  0.836067  0.992133  0.989866   \n",
       "2    LR  0.847496  0.849565  0.850218  0.847206  0.848730  0.962331  0.963064   \n",
       "\n",
       "       3LET      4LET      5LET  \n",
       "0  0.987866  0.985666  0.988866  \n",
       "1  0.990933  0.991933  0.990733  \n",
       "2  0.962064  0.961997  0.962331  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"APPENDIX TABLE 2.1: TEST SET RAW SCORES PERFORMACE ON ACCURACY METRIC\")\n",
    "columns = [\"MODEL\",\n",
    "          \"1ADL\", \"2ADL\", \"3ADL\", \"4ADL\", \"5ADL\",\n",
    "          \"1LET\", \"2LET\", \"3LET\", \"4LET\", \"5LET\",\n",
    "          \"1MUSH\", \"2MUSH\", \"3MUSH\", \"4MUSH\", \"5MUSH\",\n",
    "          \"1WTH\", \"2WTH\",\"3WTH\",\"4WTH\",\"5WTH\"]\n",
    "\n",
    "acc_rf = [\"RF\"] + rf_raw_acc\n",
    "acc_knn = [\"KNN\"] + knn_raw_acc\n",
    "acc_lr = [\"LR\"] + log_raw_acc\n",
    "\n",
    "apptable_21 = pd.DataFrame(data=[acc_rf, acc_knn, acc_lr], columns=columns)\n",
    "apptable_21.iloc[:, 0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1MUSH</th>\n",
       "      <th>2MUSH</th>\n",
       "      <th>3MUSH</th>\n",
       "      <th>4MUSH</th>\n",
       "      <th>5MUSH</th>\n",
       "      <th>1WTH</th>\n",
       "      <th>2WTH</th>\n",
       "      <th>3WTH</th>\n",
       "      <th>4WTH</th>\n",
       "      <th>5WTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.854045</td>\n",
       "      <td>0.854259</td>\n",
       "      <td>0.853656</td>\n",
       "      <td>0.853948</td>\n",
       "      <td>0.852606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.806671</td>\n",
       "      <td>0.808401</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.805115</td>\n",
       "      <td>0.806826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.854259</td>\n",
       "      <td>0.853092</td>\n",
       "      <td>0.853909</td>\n",
       "      <td>0.853306</td>\n",
       "      <td>0.852839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1MUSH  2MUSH  3MUSH  4MUSH  5MUSH      1WTH      2WTH      3WTH      4WTH  \\\n",
       "0    1.0    1.0    1.0    1.0    1.0  0.854045  0.854259  0.853656  0.853948   \n",
       "1    1.0    1.0    1.0    1.0    1.0  0.806671  0.808401  0.805970  0.805115   \n",
       "2    1.0    1.0    1.0    1.0    1.0  0.854259  0.853092  0.853909  0.853306   \n",
       "\n",
       "       5WTH  \n",
       "0  0.852606  \n",
       "1  0.806826  \n",
       "2  0.852839  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apptable_21.iloc[:, 11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAW TEST set SCORES on each metric in each trial, this one is for FSC\n",
    "log_raw_fsc = [0.658619,  0.662414,  0.660714,  0.648858,  0.651101,\n",
    "              0.000000,  0.000000,  0.000000,  0.000000,  0.000000,\n",
    "              1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "               0.624669,  0.620821,  0.620937,  0.616581,  0.623143]\n",
    "\n",
    "knn_raw_fsc = [0.635252,  0.628240,  0.617463,  0.632594,  0.632653,\n",
    "              0.895760,  0.865724,  0.880282,  0.893953,  0.879654,\n",
    "              1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "               0.415766,  0.416877,  0.405865,  0.409531,  0.415527]\n",
    "\n",
    "rf_raw_fsc = [0.657136,  0.669200,  0.657570,  0.664313,  0.661006,\n",
    "             0.814668,  0.817374,  0.818725,  0.790650,  0.828571,\n",
    "             1.0,      1.0,      1.0,      1.0,     1.0,\n",
    "              0.610177,  0.610259,  0.617980,  0.598914,  0.610656]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPENDIX TABLE 2.2: TEST SET RAW SCORES PERFORMACE ON F-Score METRIC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>1ADL</th>\n",
       "      <th>2ADL</th>\n",
       "      <th>3ADL</th>\n",
       "      <th>4ADL</th>\n",
       "      <th>5ADL</th>\n",
       "      <th>1LET</th>\n",
       "      <th>2LET</th>\n",
       "      <th>3LET</th>\n",
       "      <th>4LET</th>\n",
       "      <th>5LET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.657136</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>0.657570</td>\n",
       "      <td>0.664313</td>\n",
       "      <td>0.661006</td>\n",
       "      <td>0.814668</td>\n",
       "      <td>0.817374</td>\n",
       "      <td>0.818725</td>\n",
       "      <td>0.790650</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.635252</td>\n",
       "      <td>0.628240</td>\n",
       "      <td>0.617463</td>\n",
       "      <td>0.632594</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.895760</td>\n",
       "      <td>0.865724</td>\n",
       "      <td>0.880282</td>\n",
       "      <td>0.893953</td>\n",
       "      <td>0.879654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.658619</td>\n",
       "      <td>0.662414</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.648858</td>\n",
       "      <td>0.651101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MODEL      1ADL      2ADL      3ADL      4ADL      5ADL      1LET      2LET  \\\n",
       "0    RF  0.657136  0.669200  0.657570  0.664313  0.661006  0.814668  0.817374   \n",
       "1   KNN  0.635252  0.628240  0.617463  0.632594  0.632653  0.895760  0.865724   \n",
       "2    LR  0.658619  0.662414  0.660714  0.648858  0.651101  0.000000  0.000000   \n",
       "\n",
       "       3LET      4LET      5LET  \n",
       "0  0.818725  0.790650  0.828571  \n",
       "1  0.880282  0.893953  0.879654  \n",
       "2  0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"APPENDIX TABLE 2.2: TEST SET RAW SCORES PERFORMACE ON F-Score METRIC\")\n",
    "columns = [\"MODEL\",\n",
    "          \"1ADL\", \"2ADL\", \"3ADL\", \"4ADL\", \"5ADL\",\n",
    "          \"1LET\", \"2LET\", \"3LET\", \"4LET\", \"5LET\",\n",
    "          \"1MUSH\", \"2MUSH\", \"3MUSH\", \"4MUSH\", \"5MUSH\",\n",
    "          \"1WTH\", \"2WTH\",\"3WTH\",\"4WTH\",\"5WTH\"]\n",
    "\n",
    "fsc_rf = [\"RF\"] + rf_raw_fsc\n",
    "fsc_knn = [\"KNN\"] + knn_raw_fsc\n",
    "fsc_lr = [\"LR\"] + log_raw_fsc\n",
    "\n",
    "apptable_22 = pd.DataFrame(data=[fsc_rf, fsc_knn, fsc_lr], columns=columns)\n",
    "apptable_22.iloc[:, 0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1MUSH</th>\n",
       "      <th>2MUSH</th>\n",
       "      <th>3MUSH</th>\n",
       "      <th>4MUSH</th>\n",
       "      <th>5MUSH</th>\n",
       "      <th>1WTH</th>\n",
       "      <th>2WTH</th>\n",
       "      <th>3WTH</th>\n",
       "      <th>4WTH</th>\n",
       "      <th>5WTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.610177</td>\n",
       "      <td>0.610259</td>\n",
       "      <td>0.617980</td>\n",
       "      <td>0.598914</td>\n",
       "      <td>0.610656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.415766</td>\n",
       "      <td>0.416877</td>\n",
       "      <td>0.405865</td>\n",
       "      <td>0.409531</td>\n",
       "      <td>0.415527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.624669</td>\n",
       "      <td>0.620821</td>\n",
       "      <td>0.620937</td>\n",
       "      <td>0.616581</td>\n",
       "      <td>0.623143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1MUSH  2MUSH  3MUSH  4MUSH  5MUSH      1WTH      2WTH      3WTH      4WTH  \\\n",
       "0    1.0    1.0    1.0    1.0    1.0  0.610177  0.610259  0.617980  0.598914   \n",
       "1    1.0    1.0    1.0    1.0    1.0  0.415766  0.416877  0.405865  0.409531   \n",
       "2    1.0    1.0    1.0    1.0    1.0  0.624669  0.620821  0.620937  0.616581   \n",
       "\n",
       "       5WTH  \n",
       "0  0.610656  \n",
       "1  0.415527  \n",
       "2  0.623143  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apptable_22.iloc[:, 11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAW TEST set SCORES on each metric in each trial, this one is for ROC\n",
    "log_raw_roc = [0.903878,  0.904139,  0.903968,  0.905178,  0.904846,\n",
    "              0.858444,  0.859928,  0.857098,  0.862397,  0.853068,\n",
    "              1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "              0.884416,  0.884626,  0.885708,  0.884818,  0.883683]\n",
    "\n",
    "knn_raw_roc = [0.889834,  0.888025,  0.890112,  0.887853,  0.887768,\n",
    "              0.991464,  0.994721,  0.995173,  0.994100,  0.994624,\n",
    "              1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "               0.839923,  0.831548,  0.839641,  0.840887,  0.831302]\n",
    "\n",
    "rf_raw_roc = [0.903035,  0.901272,  0.902482,  0.901470,  0.901587,\n",
    "             0.997133,  0.995457,  0.997112,  0.994531,  0.997793,\n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             0.882664,  0.882683,  0.879023,  0.882971,  0.880860]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPENDIX TABLE 2.3: TEST SET RAW SCORES PERFORMACE ON ROC METRIC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>1ADL</th>\n",
       "      <th>2ADL</th>\n",
       "      <th>3ADL</th>\n",
       "      <th>4ADL</th>\n",
       "      <th>5ADL</th>\n",
       "      <th>1LET</th>\n",
       "      <th>2LET</th>\n",
       "      <th>3LET</th>\n",
       "      <th>4LET</th>\n",
       "      <th>5LET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.903035</td>\n",
       "      <td>0.901272</td>\n",
       "      <td>0.902482</td>\n",
       "      <td>0.901470</td>\n",
       "      <td>0.901587</td>\n",
       "      <td>0.997133</td>\n",
       "      <td>0.995457</td>\n",
       "      <td>0.997112</td>\n",
       "      <td>0.994531</td>\n",
       "      <td>0.997793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.889834</td>\n",
       "      <td>0.888025</td>\n",
       "      <td>0.890112</td>\n",
       "      <td>0.887853</td>\n",
       "      <td>0.887768</td>\n",
       "      <td>0.991464</td>\n",
       "      <td>0.994721</td>\n",
       "      <td>0.995173</td>\n",
       "      <td>0.994100</td>\n",
       "      <td>0.994624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.903878</td>\n",
       "      <td>0.904139</td>\n",
       "      <td>0.903968</td>\n",
       "      <td>0.905178</td>\n",
       "      <td>0.904846</td>\n",
       "      <td>0.858444</td>\n",
       "      <td>0.859928</td>\n",
       "      <td>0.857098</td>\n",
       "      <td>0.862397</td>\n",
       "      <td>0.853068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MODEL      1ADL      2ADL      3ADL      4ADL      5ADL      1LET      2LET  \\\n",
       "0    RF  0.903035  0.901272  0.902482  0.901470  0.901587  0.997133  0.995457   \n",
       "1   KNN  0.889834  0.888025  0.890112  0.887853  0.887768  0.991464  0.994721   \n",
       "2    LR  0.903878  0.904139  0.903968  0.905178  0.904846  0.858444  0.859928   \n",
       "\n",
       "       3LET      4LET      5LET  \n",
       "0  0.997112  0.994531  0.997793  \n",
       "1  0.995173  0.994100  0.994624  \n",
       "2  0.857098  0.862397  0.853068  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"APPENDIX TABLE 2.3: TEST SET RAW SCORES PERFORMACE ON ROC METRIC\")\n",
    "columns = [\"MODEL\",\n",
    "          \"1ADL\", \"2ADL\", \"3ADL\", \"4ADL\", \"5ADL\",\n",
    "          \"1LET\", \"2LET\", \"3LET\", \"4LET\", \"5LET\",\n",
    "          \"1MUSH\", \"2MUSH\", \"3MUSH\", \"4MUSH\", \"5MUSH\",\n",
    "          \"1WTH\", \"2WTH\",\"3WTH\",\"4WTH\",\"5WTH\"]\n",
    "\n",
    "roc_rf = [\"RF\"] + rf_raw_roc\n",
    "roc_knn = [\"KNN\"] + knn_raw_roc\n",
    "roc_lr = [\"LR\"] + log_raw_roc\n",
    "\n",
    "apptable_23 = pd.DataFrame(data=[roc_rf, roc_knn, roc_lr], columns=columns)\n",
    "apptable_23.iloc[:, :11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apptable_23.iloc[:, 11:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAST APPENDIX TABLE!!!! T_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An appendix table with the p-values of the comparisons across algorithms in the different\n",
    "main matter tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest accfuracy\n",
    "rf_raw_acc\n",
    "knn_raw_acc\n",
    "log_raw_acc\n",
    "\n",
    "p_acc_knn = stats.ttest_ind(rf_raw_acc, knn_raw_acc)[1]\n",
    "p_acc_lr = stats.ttest_ind(rf_raw_acc, log_raw_acc)[1]\n",
    "\n",
    "p_fsc_knn = stats.ttest_ind(rf_raw_fsc, knn_raw_fsc)[1]\n",
    "p_fsc_lr = stats.ttest_ind(rf_raw_fsc, log_raw_fsc)[1]\n",
    "\n",
    "p_roc_knn = stats.ttest_ind(rf_raw_roc, knn_raw_roc)[1]\n",
    "p_roc_lr = stats.ttest_ind(rf_raw_roc, log_raw_roc)[1]\n",
    "\n",
    "p_values_2 = [[\"RF/ACC\"]+[p_acc_knn, p_acc_lr], \n",
    "              [\"RF/FSC\"]+[p_fsc_knn, p_fsc_lr], \n",
    "              [\"RF/ROC\"]+[p_roc_knn, p_roc_lr]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPENDIX TABLE 3.1: P-value for Table 2 (RF compared with KNN/LR)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL/METRIC</th>\n",
       "      <th>p-val KNN</th>\n",
       "      <th>p-val LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF/ACC</td>\n",
       "      <td>0.573259</td>\n",
       "      <td>0.754419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF/FSC</td>\n",
       "      <td>0.526971</td>\n",
       "      <td>0.030323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF/ROC</td>\n",
       "      <td>0.457459</td>\n",
       "      <td>0.063920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MODEL/METRIC  p-val KNN  p-val LR\n",
       "0       RF/ACC   0.573259  0.754419\n",
       "1       RF/FSC   0.526971  0.030323\n",
       "2       RF/ROC   0.457459  0.063920"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"APPENDIX TABLE 3.1: P-value for Table 2 (RF compared with KNN/LR)\")\n",
    "columns=[\"MODEL/METRIC\", \"p-val KNN\", \"p-val LR\"]\n",
    "\n",
    "apptable_31 = pd.DataFrame(data=p_values_2, columns=columns)\n",
    "apptable_31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table, the algorithm with the best performance\n",
    "on each metric is boldfaced. Other algorithm’s whose\n",
    "performance is not statistically distinguishable from\n",
    "the best algorithm at p = 0.05 using paired t-tests on\n",
    "the 5 trials are *’ed. Entries in the table that are\n",
    "neither bold nor starred indicate performance that is\n",
    "significantly lower than the best models at p = 0.05.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_adult = [0.847496,  0.849565,  0.850218,  0.847206,  0.848730,\n",
    "            0.903878,  0.904139,  0.903968,  0.905178,  0.904846,\n",
    "            0.658619,  0.662414,  0.660714,  0.648858,  0.651101]\n",
    "log_letters = [0.962331,  0.963064,  0.962064,  0.961997,  0.962331,\n",
    "              0.858444,  0.859928,  0.857098,  0.862397,  0.853068,\n",
    "              0.000000,  0.000000,  0.000000,  0.000000,  0.000000]\n",
    "log_mush = [1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "            1.0,      1.0,      1.0,      1.0,      1.0]\n",
    "log_weather = [0.854259,  0.853092,  0.853909,  0.853306,  0.852839,\n",
    "              0.884416,  0.884626,  0.885708,  0.884818,  0.883683,\n",
    "              0.624669,  0.620821,  0.620937,  0.616581,  0.623143]\n",
    "\n",
    "knn_adult = [0.837627,  0.836502,  0.836865, 0.833055,  0.836067,\n",
    "             0.889834,  0.888025,  0.890112, 0.887853,  0.887768,\n",
    "            0.635252,  0.628240,  0.617463,  0.632594,  0.632653]\n",
    "knn_letters = [0.992133,  0.989866,  0.990933,  0.991933,  0.990733,\n",
    "                0.991464,  0.994721,  0.995173,  0.994100,  0.994624,\n",
    "                0.895760,  0.865724, 0.880282,  0.893953,  0.879654]\n",
    "knn_mush = [1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "            1.0,      1.0,      1.0,      1.0,      1.0]\n",
    "knn_weather = [0.806671,  0.808401,  0.805970,  0.805115, 0.806826,\n",
    "                0.839923,  0.831548,  0.839641,  0.840887, 0.831302,\n",
    "                0.415766,  0.416877,  0.405865, 0.409531, 0.415527]\n",
    "\n",
    "rf_adult = [0.850689,  0.852721,  0.849746,  0.852068,  0.850798,\n",
    "             0.903035,  0.901272,  0.902482,  0.901470,  0.901587,\n",
    "            0.657136,  0.669200,  0.657570,  0.664313,  0.661006]\n",
    "rf_letters = [0.988066,  0.987799,  0.987866,  0.985666,  0.988866,\n",
    "            0.997133,  0.995457,  0.997112,  0.994531,  0.997793,\n",
    "            0.814668,  0.817374,  0.818725,  0.790650,  0.828571]\n",
    "rf_mush = [1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "             1.0,      1.0,      1.0,      1.0,      1.0,\n",
    "            1.0,      1.0,      1.0,      1.0,      1.0]\n",
    "rf_weather = [0.854045,  0.854259,  0.853656,  0.853948,  0.852606,\n",
    "            0.882664,  0.882683,  0.879023,  0.882971,  0.880860,\n",
    "            0.610177,  0.610259,  0.617980,  0.598914,  0.610656]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ADULT(KNN)', 0.621420836715286],\n",
       " ['ADULT(LR)', 0.962548117088441],\n",
       " ['LETTERS.O(KNN)', 0.3846779953889695],\n",
       " ['LETTERS.O(LR)', 0.00972807689062472],\n",
       " ['MUSHROOM(KNN)', nan],\n",
       " ['MUSHROOM(LR)', nan],\n",
       " ['WEATHER(KNN)', 0.12614739316961557],\n",
       " ['WEATHER(LR)', 0.9162883676312776]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_knn = stats.ttest_ind(rf_adult, knn_adult)[1]\n",
    "adult_lr = stats.ttest_ind(rf_adult, log_adult)[1]\n",
    "\n",
    "letters_knn = stats.ttest_ind(rf_letters, knn_letters)[1]\n",
    "letters_lr = stats.ttest_ind(rf_letters, log_letters)[1]\n",
    "\n",
    "mush_knn = stats.ttest_ind(rf_mush, knn_mush)[1]\n",
    "mush_lr = stats.ttest_ind(rf_mush, log_mush)[1]\n",
    "\n",
    "weather_knn = stats.ttest_ind(rf_weather, knn_weather)[1]\n",
    "weather_lr = stats.ttest_ind(rf_weather, log_weather)[1]\n",
    "\n",
    "p_value_3 = [[\"ADULT(KNN)\"] + [adult_knn], \n",
    "             [\"ADULT(LR)\"] + [adult_lr], \n",
    "             [\"LETTERS.O(KNN)\"] + [letters_knn], \n",
    "             [\"LETTERS.O(LR)\"] + [letters_lr],\n",
    "             [\"MUSHROOM(KNN)\"] + [mush_knn],\n",
    "             [\"MUSHROOM(LR)\"] + [mush_lr],\n",
    "             [\"WEATHER(KNN)\"] + [weather_knn],\n",
    "             [\"WEATHER(LR)\"] + [weather_lr]]\n",
    "p_value_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPENDIX TABLE 3.2: P-value for Table 3 (RF compared with other datasets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATASET(MODEL)</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADULT(KNN)</td>\n",
       "      <td>0.621421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADULT(LR)</td>\n",
       "      <td>0.962548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LETTERS.O(KNN)</td>\n",
       "      <td>0.384678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LETTERS.O(LR)</td>\n",
       "      <td>0.009728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MUSHROOM(KNN)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MUSHROOM(LR)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WEATHER(KNN)</td>\n",
       "      <td>0.126147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WEATHER(LR)</td>\n",
       "      <td>0.916288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DATASET(MODEL)        RF\n",
       "0      ADULT(KNN)  0.621421\n",
       "1       ADULT(LR)  0.962548\n",
       "2  LETTERS.O(KNN)  0.384678\n",
       "3   LETTERS.O(LR)  0.009728\n",
       "4   MUSHROOM(KNN)       NaN\n",
       "5    MUSHROOM(LR)       NaN\n",
       "6    WEATHER(KNN)  0.126147\n",
       "7     WEATHER(LR)  0.916288"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"APPENDIX TABLE 3.2: P-value for Table 3 (RF compared with other datasets)\")\n",
    "\n",
    "columns=[\"DATASET(MODEL)\", \"RF\"]\n",
    "\n",
    "apptable_32 = pd.DataFrame(data=p_value_3, columns=columns)\n",
    "apptable_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
